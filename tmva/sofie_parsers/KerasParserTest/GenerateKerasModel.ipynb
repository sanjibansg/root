{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fad4a1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models, Input, saving\n",
    "import numpy as np\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c1cbbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1639 - mae: 0.3192\n"
     ]
    }
   ],
   "source": [
    "x_train = random.rand(10)\n",
    "y_train = random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(1,)),  \n",
    "    layers.Activation(activation='relu')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "model.save('ReLU_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98e58047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1779 - mae: 0.3803\n"
     ]
    }
   ],
   "source": [
    "x_train = random.rand(10)\n",
    "y_train = random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(1,)),  \n",
    "    layers.Activation(activation='tanh')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "model.save('Tanh_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c7adaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3393 - mae: 0.4660\n"
     ]
    }
   ],
   "source": [
    "x_train = random.rand(10)\n",
    "y_train = random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(1,)),  \n",
    "    layers.Activation(activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "model.save('Softmax_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dd7bd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_train_function.<locals>.train_function at 0x762a4c671990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0918 - mae: 0.2753\n"
     ]
    }
   ],
   "source": [
    "x_train = random.rand(10)\n",
    "y_train = random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(1,)),  \n",
    "    layers.Activation(activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "model.save('Sigmoid_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19274242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x762a4c673f40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1316 - mae: 0.2668\n"
     ]
    }
   ],
   "source": [
    "x_train = random.rand(10)\n",
    "y_train = random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(1,)),  \n",
    "    layers.Activation(activation='selu')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "model.save('Selu_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec34f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2281 - mae: 0.3766\n"
     ]
    }
   ],
   "source": [
    "x_train = random.rand(10)\n",
    "y_train = random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(1,)),  \n",
    "    layers.Activation(activation='LeakyReLU')       # cannot extract 'alpha' from this type of declaration \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "model.save('LeakyReLU_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d269f8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1544 - mae: 0.3229\n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(32, 10)\n",
    "y_train = np.random.rand(32, 10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    Input(shape=(1,)),\n",
    "    layers.Activation(activation='swish')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('Swish_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be4a066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 168ms/step - loss: 1.3804 - mae: 1.0842\n"
     ]
    }
   ],
   "source": [
    "x_train = random.rand(10)\n",
    "y_train = random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(1,)),  \n",
    "    layers.BatchNormalization()\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "model.save('BatchNormalization_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ee8ccdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 125ms/step - loss: 1.2556 - mae: 1.0577\n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(32, 10, 10, 3)\n",
    "y_train = np.random.rand(32, 10, 10, 3)\n",
    "\n",
    "input_tensor = Input(shape=(10, 10, 3))\n",
    "\n",
    "model = models.Sequential([\n",
    "    input_tensor,\n",
    "    layers.Convolution2D(kernel_size=1, filters=1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('Conv2D_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ea48b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1650 - mae: 0.3313\n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(32, 5, 2)\n",
    "y_train = np.random.rand(32, 10)\n",
    "input_tensor = Input(shape=(5, 2))\n",
    "\n",
    "model = models.Sequential([\n",
    "    input_tensor,\n",
    "    layers.Flatten()\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('Flatten_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de0b3956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 797ms/step - loss: 0.4269 - mae: 0.5609\n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(10, 1, 1)  \n",
    "y_train = np.random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.GRU(10, input_shape = (1, 1))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('GRU_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0392039b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 774ms/step - loss: 0.2568 - mae: 0.4064\n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(10, 1, 1)  \n",
    "y_train = np.random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.GRU(10, input_shape = (1, 1), use_bias=True)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('GRU_with_bias_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7581746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 881ms/step - loss: 0.2423 - mae: 0.4198\n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(10, 1, 1)  \n",
    "y_train = np.random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.LSTM(units=10, input_shape = (1, 1))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('LSTM_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca978d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 748ms/step - loss: 0.1709 - mae: 0.3541\n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(10, 1, 1)  \n",
    "y_train = np.random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.LSTM(units=10, input_shape = (1, 1), use_bias=True)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('LSTM_with_bias_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13519b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 338ms/step - loss: 0.2810 - mae: 0.4114\n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(10, 1, 1)  \n",
    "y_train = np.random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.SimpleRNN(10, input_shape = (1, 1))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('Simple_RNN_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38052dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 325ms/step - loss: 0.1479 - mae: 0.3399\n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(10, 1, 1)  \n",
    "y_train = np.random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.SimpleRNN(10, input_shape = (1, 1), use_bias=True)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('Simple_RNN_with_bias_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b519732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 126ms/step - loss: 0.6348 - mae: 0.6387\n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(32, 10, 10)\n",
    "y_train = np.random.rand(32, 10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    Input(shape=(10,10)),\n",
    "    layers.Reshape((100,)),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('MLP_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c278d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1665 - mae: 0.3342\n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(32, 10, 10)\n",
    "y_train = np.random.rand(32, 100)\n",
    "\n",
    "model = models.Sequential([\n",
    "    Input(shape=(10,10)),\n",
    "    layers.Reshape((100,))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('Reshape_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9af335b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "input1 = layers.Input(shape=(16,))\n",
    "x1 = layers.Dense(8, activation='relu')(input1)\n",
    "input2 = layers.Input(shape=(32,))\n",
    "x2 = layers.Dense(8, activation='relu')(input2)\n",
    "# equivalent to `added = keras.layers.add([x1, x2])`\n",
    "added = layers.Add()([x1, x2])\n",
    "out = layers.Dense(4)(added)\n",
    "model = models.Model(inputs=[input1, input2], outputs=out)\n",
    "\n",
    "model.save('Add_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c089d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1997 - mae: 0.3662\n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(32, 10, 10, 3)\n",
    "y_train = np.random.rand(32, 5, 5, 3)\n",
    "\n",
    "model = models.Sequential([\n",
    "    Input(shape=(10, 10, 3)),\n",
    "    layers.MaxPool2D(pool_size=(2, 2))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('MaxPool2D_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02df261a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
