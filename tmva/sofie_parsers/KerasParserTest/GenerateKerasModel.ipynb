{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad4a1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 12:55:27.396195: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-10 12:55:27.404396: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-10 12:55:27.479425: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-10 12:55:27.549167: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-10 12:55:27.602782: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-10 12:55:27.628601: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-10 12:55:27.752548: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-10 12:55:29.362287: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models, Input, saving\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from pprint import pp\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9790aec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 0.1977 - mae: 0.3673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasanna/RootDevelopment/py310/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:83: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(32, 10, 10, 3)\n",
    "y_train = np.random.rand(32, 5, 5, 3)\n",
    "\n",
    "model = models.Sequential([\n",
    "    Input(shape=(10, 10, 3)),\n",
    "    layers.MaxPool2D(pool_size=(2, 2))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('MaxPool2D_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "576e2378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_tracker': <keras.src.utils.tracking.Tracker at 0x75a9b044d780>,\n",
       " '_self_setattr_tracking': True,\n",
       " '_trainable_variables': [],\n",
       " '_non_trainable_variables': [],\n",
       " '_layers': [<InputLayer name=input_layer, built=True>,\n",
       "  <MaxPooling2D name=max_pooling2d, built=True>],\n",
       " '_metrics': [],\n",
       " '_seed_generators': [],\n",
       " '_lock': False,\n",
       " '_auto_config': <keras.src.saving.serialization_lib.SerializableDict at 0x75a9b044e7a0>,\n",
       " 'build': <function keras.src.models.sequential.Sequential.build(input_shape=None)>,\n",
       " 'quantize': <function keras.src.models.model.Model.quantize(mode, **kwargs)>,\n",
       " '_run_eagerly': False,\n",
       " '_jit_compile': False,\n",
       " 'compiled': True,\n",
       " 'loss': <function keras.src.losses.losses.mean_squared_error(y_true, y_pred)>,\n",
       " 'steps_per_execution': 1,\n",
       " '_initial_epoch': None,\n",
       " '_compute_loss_has_training_arg': True,\n",
       " '_compile_loss': <keras.src.trainers.compile_utils.CompileLoss at 0x75a9b02dc370>,\n",
       " '_compile_metrics': <CompileMetrics name=compile_metrics>,\n",
       " '_loss_tracker': <Mean name=loss>,\n",
       " 'train_function': None,\n",
       " 'test_function': None,\n",
       " 'predict_function': None,\n",
       " 'unrolled_steps_per_execution': 1,\n",
       " '_distribute_strategy': None,\n",
       " '_saved_model_inputs_spec': None,\n",
       " '_saved_model_arg_spec': None,\n",
       " '_tracked': ['_inbound_nodes',\n",
       "  '_outbound_nodes',\n",
       "  '_losses',\n",
       "  '_loss_ids',\n",
       "  '_losses_override',\n",
       "  'call_signature_parameters',\n",
       "  '_call_context_args',\n",
       "  '_call_has_context_arg',\n",
       "  '_layers',\n",
       "  '_build_shapes_dict'],\n",
       " '_dtype_policy': <DTypePolicy \"float32\">,\n",
       " 'name': 'sequential',\n",
       " '_inbound_nodes': [],\n",
       " '_outbound_nodes': [],\n",
       " 'activity_regularizer': None,\n",
       " '_path': 'sequential',\n",
       " 'built': True,\n",
       " 'autocast': True,\n",
       " '_input_spec': None,\n",
       " '_called': False,\n",
       " 'supports_jit': True,\n",
       " '_trainable': True,\n",
       " '_losses': [],\n",
       " '_loss_ids': TrackedSet(),\n",
       " '_losses_override': [],\n",
       " '_call_signature': <Signature (inputs, training=None, mask=None, **kwargs)>,\n",
       " 'call_signature_parameters': ['inputs', 'training', 'mask', 'kwargs'],\n",
       " '_call_has_training_arg': True,\n",
       " '_call_has_mask_arg': True,\n",
       " '_call_context_args': {'training'},\n",
       " '_call_has_context_arg': {'training': True},\n",
       " '_supports_masking': False,\n",
       " '_convert_input_args': True,\n",
       " '_allow_non_tensor_positional_args': False,\n",
       " '_build_shapes_dict': {'input_shape': (None, 10, 10, 3)},\n",
       " '_parent_path': '',\n",
       " '_remat_mode': None,\n",
       " '_functional': <Functional name=functional_4, built=True>,\n",
       " '_self_unconditional_checkpoint_dependencies': [TrackableReference(name=_functional, ref=<Functional name=functional_4, built=True>),\n",
       "  TrackableReference(name=optimizer, ref=<keras.src.optimizers.adam.Adam object at 0x75a9b02dd960>)],\n",
       " '_self_unconditional_dependency_names': {'_functional': <Functional name=functional_4, built=True>,\n",
       "  'optimizer': <keras.src.optimizers.adam.Adam at 0x75a9b02dd960>},\n",
       " '_self_unconditional_deferred_dependencies': {},\n",
       " '_self_update_uid': -1,\n",
       " '_self_name_based_restores': TrackedSet(),\n",
       " '_self_saveable_object_factories': {},\n",
       " 'optimizer': <keras.src.optimizers.adam.Adam at 0x75a9b02dd960>,\n",
       " 'stop_training': False,\n",
       " '_compile_config': <keras.src.saving.serialization_lib.SerializableDict at 0x75a9b02ddf90>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('MaxPool2D_test.h5')\n",
    "\n",
    "# for layer in model.layers:\n",
    "#     pp(layer.__dict__)\n",
    "\n",
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69d933fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "input1 = layers.Input(shape=(16,))\n",
    "x1 = layers.Dense(8, activation='relu')(input1)\n",
    "input2 = layers.Input(shape=(32,))\n",
    "x2 = layers.Dense(8, activation='relu')(input2)\n",
    "# equivalent to `added = keras.layers.add([x1, x2])`\n",
    "added = layers.Add()([x1, x2])\n",
    "out = layers.Dense(4)(added)\n",
    "model = models.Model(inputs=[input1, input2], outputs=out)\n",
    "\n",
    "model.save('Add_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ebd0f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_layer_26\n",
      "input_layer_27\n",
      "keras_tensor_136\n",
      "keras_tensor_138\n",
      "keras_tensor_141\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('Add_test.h5')\n",
    "\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer.input, list):\n",
    "        for x in layer.input:\n",
    "            print(x.name)\n",
    "    else:\n",
    "        print(layer.input.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c1cbbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - loss: 0.2668 - mae: 0.4394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = random.rand(10)\n",
    "y_train = random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(1,)),  \n",
    "    layers.Dense(10),\n",
    "    # layers.Dense(10),\n",
    "    layers.ReLU()\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('ReLU_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d8425cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Variable path=sequential_1/dense/kernel, shape=(1, 10), dtype=float32, value=[[-0.18609977  0.24831185 -0.5083592  -0.42876896 -0.43191046 -0.22159195\n",
      "   0.5433386   0.5953609   0.6934757   0.26580215]]>\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    if len(layer.weights) > 0:\n",
    "        print(layer.weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1753352f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.0\n",
      "[]\n",
      "[]\n",
      "<KerasTensor shape=(None, 16), dtype=float32, sparse=False, ragged=False, name=input_layer_18>\n",
      "<KerasTensor shape=(None, 32), dtype=float32, sparse=False, ragged=False, name=input_layer_19>\n",
      "[<KerasTensor shape=(None, 8), dtype=float32, sparse=False, ragged=False, name=keras_tensor_7>, <KerasTensor shape=(None, 8), dtype=float32, sparse=False, ragged=False, name=keras_tensor_9>]\n",
      "<KerasTensor shape=(None, 8), dtype=float32, sparse=False, ragged=False, name=keras_tensor_12>\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)\n",
    "\n",
    "# print(model.inputs)\n",
    "# print(model.outputs)\n",
    "\n",
    "model = keras.models.load_model('Add_test.h5')\n",
    "\n",
    "for layer in model.layers:\n",
    "    # print(layer.input.name)\n",
    "    # print(output_layer_name)\n",
    "    print(layer.input)\n",
    "\n",
    "# print(model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e358b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(keras.__version__) > '2.15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e58047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0976 - mae: 0.2723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = random.rand(10)\n",
    "y_train = random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(1,)),  \n",
    "    layers.Activation(activation='tanh')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "model.save('Tanh_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c7adaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasanna/RootDevelopment/py310/lib/python3.10/site-packages/keras/src/ops/nn.py:944: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.1616 - mae: 0.3141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = random.rand(10)\n",
    "y_train = random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(1,)),  \n",
    "    layers.Activation(activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "model.save('Softmax_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dd7bd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x7f74946857e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x7f74946857e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0641 - mae: 0.1915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = random.rand(10)\n",
    "y_train = random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(1,)),  \n",
    "    layers.Activation(activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "model.save('Sigmoid_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19274242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x7f749c5f24d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x7f749c5f24d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.3230 - mae: 0.4993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = random.rand(10)\n",
    "y_train = random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(1,)),  \n",
    "    layers.Activation(activation='selu')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "model.save('Selu_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ec34f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.2197 - mae: 0.3973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = random.rand(10)\n",
    "y_train = random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(1,)),  \n",
    "    layers.LeakyReLU()      # cannot extract 'alpha' from this type of declaration \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "model.save('LeakyReLU_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a04d1b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model.layers:\n",
    "#     print(layer.__dict__['activation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d269f8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.1694 - mae: 0.3394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(32, 10)\n",
    "y_train = np.random.rand(32, 10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    Input(shape=(1,)),\n",
    "    layers.Activation(activation='swish')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('Swish_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4be4a066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step - loss: 1.4358 - mae: 1.0595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = random.rand(10)\n",
    "y_train = random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(1,)),  \n",
    "    layers.BatchNormalization()\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "model.save('BatchNormalization_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e97de11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'sequential_8/batch_normalization/gamma'\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    pp(layer.__dict__['gamma'].path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ee8ccdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 1.1087 - mae: 0.9530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(32, 10, 10, 3)\n",
    "y_train = np.random.rand(32, 10, 10, 3)\n",
    "\n",
    "input_tensor = Input(shape=(10, 10, 3))\n",
    "\n",
    "model = models.Sequential([\n",
    "    input_tensor,\n",
    "    layers.Conv2D(kernel_size=1, filters=1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('Conv2D_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f42a6458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_tracker': <keras.src.utils.tracking.Tracker object at 0x7f74943f7d30>,\n",
      " '_self_setattr_tracking': True,\n",
      " '_trainable_variables': [<Variable path=sequential_9/conv2d/kernel, shape=(1, 1, 3, 1), dtype=float32, value=[[[[-1.2075227 ]\n",
      "   [ 0.09553915]\n",
      "   [ 0.20022064]]]]>,\n",
      "                          <Variable path=sequential_9/conv2d/bias, shape=(1,), dtype=float32, value=[0.00099999]>],\n",
      " '_non_trainable_variables': [],\n",
      " '_layers': [],\n",
      " '_metrics': [],\n",
      " '_seed_generators': [],\n",
      " '_lock': False,\n",
      " '_auto_config': <keras.src.saving.serialization_lib.SerializableDict object at 0x7f74943f78b0>,\n",
      " 'build': <function BaseConv.build at 0x7f74945529e0>,\n",
      " 'quantize': <function Layer.quantize at 0x7f7494553370>,\n",
      " '_saved_model_inputs_spec': None,\n",
      " '_saved_model_arg_spec': None,\n",
      " '_tracked': ['_inbound_nodes',\n",
      "              '_outbound_nodes',\n",
      "              '_losses',\n",
      "              '_loss_ids',\n",
      "              '_losses_override',\n",
      "              'call_signature_parameters',\n",
      "              '_call_context_args',\n",
      "              '_call_has_context_arg',\n",
      "              '_build_shapes_dict'],\n",
      " '_dtype_policy': <DTypePolicy \"float32\">,\n",
      " 'name': 'conv2d',\n",
      " '_inbound_nodes': [<Node operation=conv2d, id=140138681851024>],\n",
      " '_outbound_nodes': [],\n",
      " 'activity_regularizer': None,\n",
      " '_path': 'sequential_9/conv2d',\n",
      " 'built': True,\n",
      " 'autocast': True,\n",
      " '_input_spec': InputSpec(min_ndim=4, axes={-1: 3}),\n",
      " '_called': True,\n",
      " 'supports_jit': True,\n",
      " '_trainable': True,\n",
      " '_losses': [],\n",
      " '_loss_ids': TrackedSet(),\n",
      " '_losses_override': [],\n",
      " '_call_signature': <Signature (inputs)>,\n",
      " 'call_signature_parameters': ['inputs'],\n",
      " '_call_has_training_arg': False,\n",
      " '_call_has_mask_arg': False,\n",
      " '_call_context_args': TrackedSet({'training'}),\n",
      " '_call_has_context_arg': {'training': False},\n",
      " '_supports_masking': False,\n",
      " '_convert_input_args': True,\n",
      " '_allow_non_tensor_positional_args': False,\n",
      " '_build_shapes_dict': {'input_shape': (None, 10, 10, 3)},\n",
      " '_parent_path': 'sequential_9',\n",
      " '_remat_mode': None,\n",
      " 'rank': 2,\n",
      " 'filters': 1,\n",
      " 'groups': 1,\n",
      " 'kernel_size': (1, 1),\n",
      " 'strides': (1, 1),\n",
      " 'dilation_rate': (1, 1),\n",
      " 'padding': 'valid',\n",
      " 'data_format': 'channels_last',\n",
      " 'activation': <function linear at 0x7f74a0d85bd0>,\n",
      " 'use_bias': True,\n",
      " 'kernel_initializer': <keras.src.initializers.random_initializers.GlorotUniform object at 0x7f74943f7e50>,\n",
      " 'bias_initializer': <keras.src.initializers.constant_initializers.Zeros object at 0x7f749459fcd0>,\n",
      " 'kernel_regularizer': None,\n",
      " 'bias_regularizer': None,\n",
      " 'kernel_constraint': None,\n",
      " 'bias_constraint': None,\n",
      " 'lora_rank': None,\n",
      " 'lora_alpha': None,\n",
      " 'lora_enabled': False,\n",
      " '_self_unconditional_checkpoint_dependencies': [TrackableReference(name=_kernel, ref=<Variable path=sequential_9/conv2d/kernel, shape=(1, 1, 3, 1), dtype=float32, value=[[[[-1.2075227 ]\n",
      "   [ 0.09553915]\n",
      "   [ 0.20022064]]]]>),\n",
      "                                                 TrackableReference(name=bias, ref=<Variable path=sequential_9/conv2d/bias, shape=(1,), dtype=float32, value=[0.00099999]>)],\n",
      " '_self_unconditional_dependency_names': {'_kernel': <Variable path=sequential_9/conv2d/kernel, shape=(1, 1, 3, 1), dtype=float32, value=[[[[-1.2075227 ]\n",
      "   [ 0.09553915]\n",
      "   [ 0.20022064]]]]>,\n",
      "                                          'bias': <Variable path=sequential_9/conv2d/bias, shape=(1,), dtype=float32, value=[0.00099999]>},\n",
      " '_self_unconditional_deferred_dependencies': {},\n",
      " '_self_update_uid': -1,\n",
      " '_self_name_based_restores': TrackedSet(),\n",
      " '_self_saveable_object_factories': {},\n",
      " '_kernel': <Variable path=sequential_9/conv2d/kernel, shape=(1, 1, 3, 1), dtype=float32, value=[[[[-1.2075227 ]\n",
      "   [ 0.09553915]\n",
      "   [ 0.20022064]]]]>,\n",
      " 'bias': <Variable path=sequential_9/conv2d/bias, shape=(1,), dtype=float32, value=[0.00099999]>}\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    pp(layer.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ea48b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.1626 - mae: 0.3247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(32, 5, 2)\n",
    "y_train = np.random.rand(32, 10)\n",
    "input_tensor = Input(shape=(5, 2))\n",
    "\n",
    "model = models.Sequential([\n",
    "    input_tensor,\n",
    "    layers.Flatten()\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('Flatten_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de0b3956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasanna/RootDevelopment/py310/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.2095 - mae: 0.3930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(10, 1, 1)  \n",
    "y_train = np.random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.GRU(1, input_shape = (1, 1))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('GRU_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c2495ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"l_st_m\"\n",
    "\n",
    "s.__contains__('lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9147a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.get_layer('gru_2').__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0392039b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.3008 - mae: 0.4915   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(10, 1, 1)  \n",
    "y_train = np.random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.GRU(10, input_shape = (1, 1), use_bias=True)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('GRU_with_bias_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7581746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4311 - mae: 0.5842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(10, 1, 1)  \n",
    "y_train = np.random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.LSTM(units=10, input_shape = (1, 1))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('LSTM_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca978d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943ms/step - loss: 0.2485 - mae: 0.3696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(10, 1, 1)  \n",
    "y_train = np.random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.LSTM(units=10, input_shape = (1, 1), use_bias=True)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('LSTM_with_bias_test.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13519b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795ms/step - loss: 0.3695 - mae: 0.4642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(10, 1, 1)  \n",
    "y_train = np.random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.SimpleRNN(10, input_shape = (1, 1))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('Simple_RNN_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38052dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691ms/step - loss: 0.3846 - mae: 0.5345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(10, 1, 1)  \n",
    "y_train = np.random.rand(10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.SimpleRNN(10, input_shape = (1, 1), use_bias=True)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('Simple_RNN_with_bias_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b519732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step - loss: 0.5155 - mae: 0.5583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(32, 10)\n",
    "y_train = np.random.rand(32, 10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(10),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('MLP_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c278d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.1706 - mae: 0.3367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(32, 10, 10)\n",
    "y_train = np.random.rand(32, 100)\n",
    "\n",
    "model = models.Sequential([\n",
    "    Input(shape=(10,10)),\n",
    "    layers.Reshape((100,))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('Reshape_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9af335b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "input1 = layers.Input(shape=(16,))\n",
    "x1 = layers.Dense(8, activation='relu')(input1)\n",
    "input2 = layers.Input(shape=(32,))\n",
    "x2 = layers.Dense(8, activation='relu')(input2)\n",
    "# equivalent to `added = keras.layers.add([x1, x2])`\n",
    "added = layers.Add()([x1, x2])\n",
    "out = layers.Dense(4)(added)\n",
    "model = models.Model(inputs=[input1, input2], outputs=out)\n",
    "\n",
    "model.save('Add_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c089d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.2050 - mae: 0.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(32, 10, 10, 3)\n",
    "y_train = np.random.rand(32, 5, 5, 3)\n",
    "\n",
    "model = models.Sequential([\n",
    "    Input(shape=(10, 10, 3)),\n",
    "    layers.MaxPool2D(pool_size=(2, 2))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.save('MaxPool2D_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02df261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPooling2D\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f870a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
